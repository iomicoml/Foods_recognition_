{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Food_Recognition_Test.ipynb.txt",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iomicoml/Foods_recognition_/blob/main/model_food_recognition_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH-rnd0k8695"
      },
      "source": [
        "### **Fill model name. Fill information about conditions in which model was trained (count of images in dataset, classes count, time of training, etc.)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eP2l0F29zL5"
      },
      "source": [
        "ABOUT_MODEL_FILE_NAME = \"INFO.txt\"\n",
        "\n",
        "info_about_model = \"\"\"\n",
        "  model_name: Faster-RCNN Inception-V2\n",
        "  count_of_classes: 5\n",
        "  average count_of_images per class: 150\n",
        "  \n",
        "  training_time: 2 hours\n",
        "  final_loss_function_value: 0.05 - 0.09\n",
        "\n",
        "  dataset: custom\n",
        "  count_of_images: 750\n",
        "  annotations_type: manual box bounding ( 'labelImg' free python application )\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XgokiJ8DJEf"
      },
      "source": [
        "# **To run all the cells sequentially just press \"ctrl+F9\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOGTfeqQ7Vtf"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "from datetime import date\n",
        "today = date.today()\n",
        "\n",
        "import re"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GheeoN_JuAfm",
        "outputId": "78abfb96-eccf-470b-bca8-7b96879737c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp \"/content/drive/My Drive/Food_Recognition/Test/label_map_util.py\" .\n",
        "!cp \"/content/drive/My Drive/Food_Recognition/Test/visualization_utils.py\" .\n",
        "\n",
        "!cp -r \"/content/drive/My Drive/Food_Recognition/Test/inference_graph\" .\n",
        "!cp -r \"/content/drive/My Drive/Food_Recognition/Test/object_detection\" .\n",
        "!cp -r \"/content/drive/My Drive/Food_Recognition/Test/training\" .\n",
        "!cp -r \"/content/drive/My Drive/Food_Recognition/Fridge_photos\" .\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymh0noY-5fLQ"
      },
      "source": [
        "import label_map_util\n",
        "import visualization_utils as vis_util\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMNxyM3556SY"
      },
      "source": [
        "# Name of the directory containing the object detection module we're using\n",
        "MODEL_NAME = 'inference_graph'\n",
        "\n",
        "# Grab path to current working directory\n",
        "CWD_PATH = os.getcwd()\n",
        "\n",
        "# Path to frozen detection graph .pb file, which contains the model that is used\n",
        "# for object detection.\n",
        "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\n",
        "\n",
        "# Path to label map file\n",
        "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\n",
        "\n",
        "# Number of classes the object detector can identify\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# Dimension of images that will be saved in inference_test dir and showed below\n",
        "DIM = (800, 600)\n",
        "\n",
        "\n",
        "# Load the label map.\n",
        "# Label maps map indices to category names, so that when our convolution\n",
        "# network predicts `5`, we know that this corresponds to `king`.\n",
        "# Here we use internal utility functions, but anything that returns a\n",
        "# dictionary mapping integers to appropriate string labels would be fine\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "images = glob.glob('Fridge_photos/' + '/*.jpg')\n",
        "\n",
        "# Load the Tensorflow model into memory.\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.compat.v1.GraphDef()\n",
        "    with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "    sess = tf.compat.v1.Session(graph=detection_graph)\n",
        "\n",
        "# Define input and output tensors (i.e. data) for the object detection classifier\n",
        "\n",
        "# Input tensor is the image\n",
        "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "# Output tensors are the detection boxes, scores, and classes\n",
        "# Each box represents a part of the image where a particular object was detected\n",
        "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "\n",
        "# Each score represents level of confidence for each of the objects.\n",
        "# The score is shown on the result image, together with the class label.\n",
        "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "\n",
        "# Number of objects detected\n",
        "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "\n",
        "\n",
        "# create new folder with date of inference testing ( (Iomicoml_acoount_drive) /Food_Recognition/Test_inference/)\n",
        "folder_id = '18VzeTeOq-uCA3-V56acSYqbAf6VV4d_m'\n",
        "file_metadata = {\n",
        "    'name': today.strftime(\"%b-%d-%Y\"),\n",
        "    'mimeType': 'application/vnd.google-apps.folder',\n",
        "    'parents': [folder_id]\n",
        "}\n",
        "\n",
        "file = drive_service.files().create(body=file_metadata,\n",
        "                                    fields='id').execute()\n",
        "\n",
        "test_inf_save_dir = file.get('id')\n",
        "\n",
        "\n",
        "for img in images:\n",
        "  image = cv2.imread(img)\n",
        "  image = cv2.resize(image,DIM, interpolation=cv2.INTER_AREA) \n",
        "  image_rgb = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
        "  image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "  # Perform the actual detection by running the model with the image as input\n",
        "  (boxes, scores, classes, num) = sess.run(\n",
        "      [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "      feed_dict={image_tensor: image_expanded})\n",
        "\n",
        "  # Draw the results of the detection (aka 'visulaize the results')\n",
        "\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image,\n",
        "      np.squeeze(boxes),\n",
        "      np.squeeze(classes).astype(np.int32),\n",
        "      np.squeeze(scores),\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8,\n",
        "      min_score_thresh=0.60)\n",
        "\n",
        "  # All the results have been drawn on image. Now display the image.\n",
        "  cv2_imshow(image)\n",
        "\n",
        "  # current image name = Fridge_photos/()..).jpg, name for image write must be only ()..).jpg, part of string after /\n",
        "  match = re.search('/(.+?)$', img)\n",
        "  if match:\n",
        "    img_name = match.group(1)\n",
        "  else:\n",
        "    img_name = img\n",
        "\n",
        "  cv2.imwrite(img_name, image)\n",
        "\n",
        "  file_metadata = {\n",
        "  'name': img_name,\n",
        "  'mimeType': 'image/jpeg',\n",
        "  'parents': [test_inf_save_dir]\n",
        "  }\n",
        "  media = MediaFileUpload(img_name, \n",
        "                        mimetype='image/jpeg',\n",
        "                        resumable=True)\n",
        "  \n",
        "  drive_service.files().create(body=file_metadata, media_body=media,fields='id').execute()\n",
        "\n",
        "  # # Press any key to close the image\n",
        "  # cv2.waitKey(0)\n",
        "  # # Clean up\n",
        "  # cv2.destroyAllWindows()\n",
        "\n",
        "# create text_file for explanation model training conditions (top of notebook)\n",
        "\n",
        "\n",
        "with open(ABOUT_MODEL_FILE_NAME, 'w') as out_file:\n",
        "  out_file.write(info_about_model)\n",
        "\n",
        "file_metadata = {\n",
        "  'name': ABOUT_MODEL_FILE_NAME,\n",
        "  'mimeType': 'text/plan',\n",
        "  'parents': [test_inf_save_dir]\n",
        "  }\n",
        "media = MediaFileUpload(ABOUT_MODEL_FILE_NAME, \n",
        "                        mimetype='text/plan',\n",
        "                        resumable=True)\n",
        "  \n",
        "drive_service.files().create(body=file_metadata, media_body=media,fields='id').execute()\n",
        "\n",
        "os.remove(ABOUT_MODEL_FILE_NAME)\n",
        "\n",
        "\n",
        "# remove all the .jpg files, that was created for save their copies in google drive inference_test dir\n",
        "cur_dir_path = os.getcwd()\n",
        "for filename in os.listdir(cur_dir_path):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        os.remove(filename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}